<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Qing Liu's Homepage</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="#" class="image avatar"><img src="images/avatar.jpg" alt="" /></a>
					<h1><strong>I am Qing Liu (刘晴)</strong>, a Senior Research Scientist/Engineer at
					<a href="https://research.adobe.com">Adobe Research</a>. Before joined Adobe, I got my PhD degree from Johns Hopkins
					Unversity, supervised by <a href="http://www.cs.jhu.edu/~ayuille/">Dr. Alan Yuille</a>.</h1>
				</div>
			</header>

		<!-- Main -->
			<div id="main">

				<!-- One -->
					<section id="bio">
						<header class="major">
							<h2>About me</h2>
						</header>
						<p>My current work mainly involves deep generative models for image synthesis and editing, amodal scene analysis and decomposition. My PhD dissertation focused on object recognition and parsing with weak supervision, including weakly supervised learning, domain adaptation (learning from synthetic), few-shot/zero-shot learning, etc.。</p>
						<div class="col-6 col-6-medium col-12-small">
							<section class="box style1">
								<h3 class="icon solid fa-user-graduate"> Education</h3>
									<ul>
										<li>
											<b>Ph.D. </b> in Computer Science, Johns Hopkins University 
										</li>
										<li>
											<b>M.S.E.</b> in Computer Science, Johns Hopkins University 
										</li>
										<li>
											<b>M.S.</b> in Molecular and Cell Biology, The University of Texas at Dallas
										</li>
										<li>
											<b>B.S.</b> in Chemistry and Psychology , Peking University
										</li>
									</ul>
							</section>
						</div>
						<ul class="actions">
							<li><a href="#publication" class="button">Publication</a></li>
							<!-- <li><a href="#Projects" class="button">Projects</a></li> -->
							<li><a href="#Experience" class="button">Experience</a></li>
						</ul>
					</section>

				<section id="publication">
						<header class="major">
							<h2>Recent Publication Highlights</h2>
						</header>
						<ul>
							<li>
								<b>Generative Image Layer Decomposition with Visual Effects.</b>
								<br>Jinrui Yang, <b>Qing Liu</b>, Yijun Li, Soo Ye Kim, Daniil Pakhomov, Mengwei Ren, Jianming Zhang, Zhe Lin, Cihang Xie, Yuyin Zhou.
								<br> CVPR 2025.
								<br>
								<!-- [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/6e9a0a72da9b76c3ebc8cc33ff10ac29-Paper-Conference.pdf" target="_blank">Paper</a>] -->
								[<a href="https://rayjryang.github.io/LayerDecomp/" target="_blank">Project Page</a>]
								[<a href="https://arxiv.org/pdf/2411.17864" target="_blank">Paper</a>]
								<!-- [<a href="" target="_blank">Code</a>]
								[<a href="" target="_blank">Slides</a>]
								[<a href="" target="_blank">Poster</a>] -->
								<br><br>
							</li>
							<li>
								<b>FINECAPTION: Compositional Image Captioning Focusing on Wherever You Want at Any Granularity.</b>
								<br>Hang Hua, <b>Qing Liu</b>, Lingzhi Zhang, Jing Shi, Zhifei Zhang, Yilin Wang, Jianming Zhang, Jiebo Luo.
								<br> CVPR 2025.
								<br>
								<!-- [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/6e9a0a72da9b76c3ebc8cc33ff10ac29-Paper-Conference.pdf" target="_blank">Paper</a>] -->
								[<a href="https://hanghuacs.github.io/FineCaption/" target="_blank">Project Page</a>]
								[<a href="https://arxiv.org/pdf/2411.15411" target="_blank">Paper</a>]
								[<a>Dataset (coming soon)</a>]
								<!-- [<a href="" target="_blank">Code</a>]
								[<a href="" target="_blank">Slides</a>]
								[<a href="" target="_blank">Poster</a>] -->
								<br><br>
							</li>
							<li>
								<b>Object-level Scene Deocclusion.</b>
								<br>Zhengzhe Liu, <b>Qing Liu</b>, Chirui Chang, Jianming Zhang, Daniil Pakhomov, Haitian Zheng, Zhe Lin, Daniel Cohen-Or, Chi-Wing Fu.
								<br> SIGGRAPH 2024.
								<br>
								<!-- [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/6e9a0a72da9b76c3ebc8cc33ff10ac29-Paper-Conference.pdf" target="_blank">Paper</a>] -->
								[<a href="https://liuzhengzhe.github.io/Deocclude-Any-Object.github.io/" target="_blank">Project Page</a>]
								[<a href="https://arxiv.org/pdf/2406.07706?" target="_blank">Paper</a>]
								<!-- [<a href="" target="_blank">Code</a>]
								[<a href="" target="_blank">Slides</a>]
								[<a href="" target="_blank">Poster</a>] -->
								<br><br>
							</li>
							<li>
								<b>UniHuman: A Unified Model for Editing Human Images in the Wild.</b>
								<br>Nannan Li, <b>Qing Liu</b>, Krishna Kumar Singh, Yilin Wang, Jianming Zhang, Bryan A. Plummer, Zhe Lin.
								<br> CVPR 2024.
								<br>
								<!-- [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/6e9a0a72da9b76c3ebc8cc33ff10ac29-Paper-Conference.pdf" target="_blank">Paper</a>] -->
								[<a href="https://arxiv.org/pdf/2312.14985.pdf" target="_blank">Paper</a>]
								[<a href="https://github.com/adobe-research/UniHuman" target="_blank">Dataset</a>]
								[<a href="https://github.com/adobe-research/UniHuman" target="_blank">Code</a>]
								<!-- [<a href="" target="_blank">Code</a>]
								[<a href="" target="_blank">Slides</a>]
								[<a href="" target="_blank">Poster</a>] -->
								<br><br>
							</li>
							<!--
							<li>
								<b>SmartMask: Context Aware High-Fidelity Mask Generation for Fine-grained Object Insertion and Layout Control.</b>
								<br> Jaskirat Singh, Jianming Zhang, <b>Qing Liu</b>, Cameron Younger Smith, Zhe Lin, Liang Zheng.
								<br> CVPR 2024.
								<br>
								[<a>Paper (coming soon)</a>]
								<br><br>
							</li>
							<li>
								<b>Amodal Scene Analysis via Holistic Occlusion Relation Inference and Generative Mask Completion.</b>
								<br>Bowen Zhang, <b>Qing Liu</b>, Jianming Zhang, Yilin Wang, Liyang Liu, Zhe Lin, Yifan Liu.
								<br> AAAI 2024 (Oral).
								<br>
								[<a href="https://github.com/adobe-research/ASWValData" target="_blank">Dataset</a>]
								[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/28526" target="_blank">Paper</a>]
								<br><br>
							</li>
							<li>
								<b>PHOTOSWAP: Personalized Subject Swapping in Images.</b>
								<br>Jing Gu, Yilin Wang, Nanxuan Zhao, Tsu-Jui Fu, Wei Xiong, <b>Qing Liu</b>, Zhifei Zhang, He Zhang, Jianming Zhang, HyunJoon Jung, Xin Eric Wang.
								<br> NeurIPS 2023.
								<br>
								[<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/6e9a0a72da9b76c3ebc8cc33ff10ac29-Paper-Conference.pdf" target="_blank">Paper</a>]
								[<a href="https://photoswap.github.io/" target="_blank">Project Page</a>]
								<br><br>
							</li>
							<li>
								<b>Scenecomposer: Any-Level Semantic Image Synthesis.</b>
								<br>Yu Zeng, Zhe Lin, Jianming Zhang, <b>Qing Liu</b>, John Collomosse, Jason Kuen, Vishal M Patel.
								<br> CVPR 2023 (Highlight).
								<br>
								[<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_SceneComposer_Any-Level_Semantic_Image_Synthesis_CVPR_2023_paper.pdf" target="_blank">Paper</a>]
								[<a href="https://zengyu.me/scenec/" target="_blank">Project Page</a>]
								<br><br>
							</li>
							<li>
								<b>Towards Open-World Segmentation of Parts.</b>
								<br>Tai-Yu Pan, <b>Qing Liu</b>, Wei-Lun Chao, Brian Price.
								<br> CVPR 2023.
								<br>
								[<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Pan_Towards_Open-World_Segmentation_of_Parts_CVPR_2023_paper.pdf" target="_blank">Paper</a>]
								<br><br>
							</li>
							<li>
								<b>Learning Part Segmentation Through Unsupervised Domain Adaptation from Synthetic Vehicles.</b>
								<br><b>Qing Liu</b>, Adam Kortylewski, Zhishuai Zhang, Zizhang Li, Mengqi Guo, Qihao Liu, Xiaoding Yuan, Jiteng Mu, Weichao Qiu, Alan Yuille.
								<br> CVPR 2022 (Oral).
								<br>
								[<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Part_Segmentation_Through_Unsupervised_Domain_Adaptation_From_Synthetic_Vehicles_CVPR_2022_paper.pdf" target="_blank">Paper</a>]
								[<a href="https://qliu24.github.io/cgpart/" target="_blank">Dataset</a>]
								<br><br>
							</li>
							-->
						</ul>
					</section>

				<!-- Two -->
				<!--
					<section id="two">
						<h2>Recent Work</h2>
						<div class="row">
							<article class="col-6 col-12-xsmall work-item">
								<a href="images/fulls/01.jpg" class="image fit thumb"><img src="images/thumbs/01.jpg" alt="" /></a>
								<h3>Magna sed consequat tempus</h3>
								<p>Lorem ipsum dolor sit amet nisl sed nullam feugiat.</p>
							</article>
							<article class="col-6 col-12-xsmall work-item">
								<a href="images/fulls/02.jpg" class="image fit thumb"><img src="images/thumbs/02.jpg" alt="" /></a>
								<h3>Ultricies lacinia interdum</h3>
								<p>Lorem ipsum dolor sit amet nisl sed nullam feugiat.</p>
							</article>
							<article class="col-6 col-12-xsmall work-item">
								<a href="images/fulls/03.jpg" class="image fit thumb"><img src="images/thumbs/03.jpg" alt="" /></a>
								<h3>Tortor metus commodo</h3>
								<p>Lorem ipsum dolor sit amet nisl sed nullam feugiat.</p>
							</article>
							<article class="col-6 col-12-xsmall work-item">
								<a href="images/fulls/04.jpg" class="image fit thumb"><img src="images/thumbs/04.jpg" alt="" /></a>
								<h3>Quam neque phasellus</h3>
								<p>Lorem ipsum dolor sit amet nisl sed nullam feugiat.</p>
							</article>
							<article class="col-6 col-12-xsmall work-item">
								<a href="images/fulls/05.jpg" class="image fit thumb"><img src="images/thumbs/05.jpg" alt="" /></a>
								<h3>Nunc enim commodo aliquet</h3>
								<p>Lorem ipsum dolor sit amet nisl sed nullam feugiat.</p>
							</article>
							<article class="col-6 col-12-xsmall work-item">
								<a href="images/fulls/06.jpg" class="image fit thumb"><img src="images/thumbs/06.jpg" alt="" /></a>
								<h3>Risus ornare lacinia</h3>
								<p>Lorem ipsum dolor sit amet nisl sed nullam feugiat.</p>
							</article>
						</div>
						<ul class="actions">
							<li><a href="#" class="button">Full Portfolio</a></li>
						</ul>
					</section>
				-->


				

		<!-- <section id="Projects" class="wrapper style3">
				<header>
					<h2>Recent Projects</h2>
				</header>
				<article id="cgpart" class="wrapper style2">
					<div class="container medium">
						<header><h3>CGPart: A Part Segmentation Dataset Based on 3D Computer Graphics Models</h3></header>
						<article class="col-6 col-12-xsmall work-item">
								<img src="projects/cgpart/cgpart_car.gif" alt="demo_car_cruiser" width="270"/><img src="projects/cgpart/cgpart_jet.gif" alt="demo_car_cruiser" width="270"/>
								<h5>Part segmentations provide a rich and detailed part-level description of objects, but their annotation requires an enormous amount of work. In this paper, we introduce CGPart, a comprehensive part segmentation dataset that provides detailed annotations on 3D CAD models, synthetic images, and real test images. To illustrate the value of CGPart, we apply it to image part segmentation through unsupervised domain adaptation (UDA). We evaluate several baseline methods by adapting top-performing UDA algorithms from related tasks to part segmentation. Moreover, we introduce a new method called Geometric-Matching Guided domain adaptation (GMG), which leverages the spatial object structure to guide the knowledge transfer from the synthetic to the real images. Experimental results demonstrate the advantage of our algorithm and reveal insights for future improvement.</h5>
						</article>
					</div>
				</article>
		</section> -->


		<section id="Experience" class="wrapper style3">
				<header>
					<h2>Experience</h2>
				</header>
				<!-- <article id="services" class="wrapper style2">
					<div class="container medium">
						<header><h2>Academic Services</h2></header>
						<ul>
							<li>
								<b>Reviewer</b>:
								CVPR 2024, 2023 2022, AAAI 2022, WACV 2022, CVPR 2021, ICCV 2021, WACV 2021, ICCV 2019
							</li>
							<li>
								<b>Teaching Assistant</b>:
								EN. 601.461/661: Computer Vision. <br>
								Johns Hopkins University - Spring 2020
							</li>
						</ul>
					</div>
				</article> -->
				<article id="working_experience" class="wrapper style2">
					<div class="container medium">
						<header><h2>Work Experience</h2></header>
						<ul>
							<li>
								<b>Senior Research Scientist/Engineer, Adobe </b>:
								2021/11-Present
							</li>
							<li>
								<b>Research Intern, Facebook AI </b>:
								2020/05-2020/09
							</li>
							<li>
								<b>Applied Scientist Intern, Amazon AWS ReKognition</b>:
								2019/06-2019/09
							</li>
							<li>
								<b>Applied Scientist Intern, Amazon Transaction Risk Management Systems</b>:
								2018/05-2018/08
							</li>
						</ul>
					</div>
				</article>
		</section>


		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="icons">
						<li><a href="https://scholar.google.com/citations?user=1ytghtEAAAAJ&hl=en" class="icon solid fa-graduation-cap"><span class="label">Google_scholar</span></a></li>
						<li><a href="https://github.com/qliu24" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<!-- <li><a href="#" class="icon brands fa-dribbble"><span class="label">Dribbble</span></a></li> -->
						<li><a id="email" href="mailto:qingliu@jhu.edu" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
						<li><a href="resume/resume_qingliu.pdf" class="icon fa-id-card"><span class="label">CV</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; Qing Liu</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>
			<button onclick="topFunction()" id="top_btn" title="Go to top">Top</button>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

			<script>
			//Get the button
			var mybutton = document.getElementById("top_btn");

			// When the user scrolls down 20px from the top of the document, show the button
			window.onscroll = function() {scrollFunction()};

			function scrollFunction() {
			  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
			    mybutton.style.display = "block";
			  } else {
			    mybutton.style.display = "none";
			  }
			}

			// When the user clicks on the button, scroll to the top of the document
			function topFunction() {
			  document.body.scrollTop = 0;
			  document.documentElement.scrollTop = 0;
			}
			</script>

	</body>
</html>